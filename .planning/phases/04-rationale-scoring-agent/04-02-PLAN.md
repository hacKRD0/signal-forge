---
phase: 04-rationale-scoring-agent
type: execute
---

<objective>
Implement rationale generation agent that explains match scores.

Purpose: Generate human-readable explanations for why each discovered entity is a good customer or partner match, grounding explanations in the match scores and business context.
Output: Rationale generator that produces detailed, specific explanations for each match.
</objective>

<execution_context>
@~/.claude/skills/create-plans/workflows/execute-phase.md
@~/.claude/skills/create-plans/templates/summary.md
</execution_context>

<context>
@.planning/BRIEF.md
@.planning/ROADMAP.md
@.planning/phases/04-rationale-scoring-agent/04-01-SUMMARY.md
@src/models/match_score.py
@src/models/discovery_results.py
@src/models/business_context.py
@src/scoring/match_scorer.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create rationale data model and prompts</name>
  <files>src/models/rationale.py, src/scoring/rationale_prompts.py</files>
  <action>
Create src/models/rationale.py:
- Dataclass: Rationale with fields:
  - summary: str (one-sentence summary of why this is a good match)
  - key_strengths: list[str] (3-5 bullet points on why match is strong)
  - fit_explanation: str (detailed explanation of fit based on scores)
  - potential_concerns: list[str] (1-2 potential challenges or gaps, if any)
  - recommendation: str (Strong Match / Good Match / Fair Match based on score)
- Methods: to_dict(), from_dict()
- Add docstrings

Create src/scoring/rationale_prompts.py:
- CUSTOMER_RATIONALE_PROMPT: Template for generating customer match rationale
  - Inputs: company info, business context, match score breakdown
  - Outputs: Rationale structure
  - Emphasize: why this company needs the business's products/services
- PARTNER_RATIONALE_PROMPT: Template for generating partner match rationale
  - Inputs: company info, business context, match score breakdown
  - Outputs: Rationale structure
  - Emphasize: complementary capabilities, synergies, partnership opportunities

Avoid: Don't make prompts too long. Include clear output format examples.
  </action>
  <verify>
- src/models/rationale.py exists
- src/scoring/rationale_prompts.py exists
- Imports work: python -c "from src.models.rationale import Rationale"
- Two prompt templates defined (customer, partner)
  </verify>
  <done>Rationale data model and prompts created</done>
</task>

<task type="auto">
  <name>Task 2: Implement rationale generator</name>
  <files>src/scoring/rationale_generator.py</files>
  <action>
Create src/scoring/rationale_generator.py:
- Class: RationaleGenerator
- __init__: Accept DiscoveryAgent
- Method: generate_rationale(company: CompanyInfo, context: BusinessContext, score: MatchScore, entity_type: str) -> Rationale
  - Select appropriate prompt (customer or partner) based on entity_type
  - Format prompt with company info, context, and score breakdown
  - Call agent to generate rationale
  - Parse response into Rationale instance
  - Determine recommendation based on overall_score:
    - >= 80: "Strong Match"
    - >= 60: "Good Match"
    - < 60: "Fair Match"
  - Return Rationale instance
- Method: batch_generate(companies_with_scores: list[tuple[CompanyInfo, MatchScore]], context: BusinessContext, entity_type: str) -> list[Rationale]
  - Generate rationales for multiple companies
  - Return list of Rationale instances
- Include error handling for parsing failures
- Add logging for generation process

Avoid: Don't generate generic rationales (use specific company and context details). Don't ignore score breakdown (ground rationale in scores).
  </action>
  <verify>
- src/scoring/rationale_generator.py exists
- Imports: python -c "from src.scoring.rationale_generator import RationaleGenerator"
- Methods defined: generate_rationale, batch_generate
- generate_rationale returns Rationale instance
  </verify>
  <done>RationaleGenerator implemented with entity-specific generation</done>
</task>

<task type="auto">
  <name>Task 3: Add rationale generation tests</name>
  <files>tests/test_rationale_generator.py</files>
  <action>
Create tests/test_rationale_generator.py:
- Test: test_rationale_model
  - Create Rationale instance
  - Verify all fields present
  - Test serialization
- Test: test_recommendation_levels
  - Score 85 → "Strong Match"
  - Score 70 → "Good Match"
  - Score 55 → "Fair Match"
- Mock test: test_generate_rationale_customer
  - Mock agent response
  - Call generate_rationale with entity_type="customer"
  - Verify Rationale returned
  - Verify customer-specific language used
- Mock test: test_generate_rationale_partner
  - Mock agent response
  - Call generate_rationale with entity_type="partner"
  - Verify partner-specific language (synergies, complementary)
- Test: test_batch_generation
  - Multiple companies
  - Verify batch processing works
  - Verify all rationales returned

Avoid: Don't test exact rationale text (will vary). Test structure and appropriate entity-type handling.
  </action>
  <verify>
- tests/test_rationale_generator.py exists
- Tests run: python -m pytest tests/test_rationale_generator.py -v
- Rationale generation logic validated
- Entity type handling verified
  </verify>
  <done>Rationale generation tests created and validated</done>
</task>

</tasks>

<verification>
Before declaring plan complete:
- [ ] Rationale data model with structured fields
- [ ] Prompts for customer and partner rationale generation
- [ ] RationaleGenerator creates entity-specific rationales
- [ ] Recommendation levels based on score thresholds
- [ ] Tests validate generation logic
</verification>

<success_criteria>
- All tasks completed
- All verification checks pass
- Rationale generation produces detailed, specific explanations
- Entity-specific rationales (customer vs partner language)
- Ready for integration with discovery pipeline
</success_criteria>

<output>
After completion, create `.planning/phases/04-rationale-scoring-agent/04-02-SUMMARY.md`:

# Phase 4 Plan 2: Rationale Generation Summary

**Rationale generation agent implemented**

## Accomplishments
- Created Rationale data model with structured explanation fields
- Implemented rationale generation prompts (customer and partner)
- Built RationaleGenerator with entity-specific generation
- Recommendation levels based on score thresholds
- Added comprehensive tests

## Files Created/Modified
- `src/models/rationale.py` - Rationale data model
- `src/scoring/rationale_prompts.py` - Generation prompts
- `src/scoring/rationale_generator.py` - RationaleGenerator class
- `tests/test_rationale_generator.py` - Rationale tests

## Decisions Made
- Structured rationale format (summary, strengths, fit, concerns, recommendation)
- Three recommendation levels (Strong/Good/Fair based on score thresholds)
- Entity-specific prompts ensure appropriate language
- Grounded rationales reference score breakdown

## Issues Encountered
[Document any issues, or "None"]

## Next Step
Ready for 04-03-PLAN.md (Integration with discovery pipeline)
</output>
